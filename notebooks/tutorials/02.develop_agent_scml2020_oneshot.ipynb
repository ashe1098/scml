{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# setup disply parameters\n",
    "from matplotlib import pylab as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "float_formatter = StrMethodFormatter('{x:0.03f}')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 20\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('figure', figsize=(18, 6)) # set figure size\n",
    "plt.rc(\"animation\", html=\"html5\")\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing an agent for SCML2021 (OneShot)\n",
    "\n",
    "In 2021, we introduced a new track called SCML-OneShot which implements a simplified problem in which the agent can focus on the many to many concurrent negotiation problem without needing to worry about long term planning or production planning as is the case with the standard and collusion tracks. \n",
    "\n",
    "An overview of the one-shot game is available [here](http://www.yasserm.com/scml/overview_oneshot.pdf) and a full description for the details-savy person is available [here](http://www.yasserm.com/scml/scml2021oneshot.pdf). We suggest that you read (or skim) these documents before continuing.\n",
    "\n",
    "Let's see the simplest possible agent (a do-nothing agent) but first, we will define a function to try our agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "from negmas import ResponseType\n",
    "from scml.oneshot import *\n",
    "from scml.scml2020 import is_system_agent\n",
    "\n",
    "def try_agent(agent_type, n_processes=2):\n",
    "    return try_agents([RandomOneShotAgent, agent_type], n_processes)\n",
    "\n",
    "def try_agents(agent_types, n_processes=2, n_trials=1, draw=False):\n",
    "    type_scores = defaultdict(float)\n",
    "    counts = defaultdict(int)\n",
    "    agent_scores = dict()\n",
    "    for _ in range(n_trials):\n",
    "        p = n_processes if isinstance(n_processes, int) else random.randint(*n_processes)\n",
    "        world = SCML2020OneShotWorld(\n",
    "        **SCML2020OneShotWorld.generate(agent_types, n_steps=10, n_processes=p), \n",
    "        construct_graphs=True,\n",
    "        )\n",
    "        world.run()\n",
    "\n",
    "        all_scores = world.scores()\n",
    "        for aid, agent in world.agents.items():\n",
    "            if is_system_agent(aid):\n",
    "                continue\n",
    "            key = aid if n_trials == 1 else f\"{aid}@{world.id[:4]}\"\n",
    "            agent_scores[key] = (\n",
    "                 agent.type_name.split('.')[-1],           \n",
    "                 all_scores[aid], \n",
    "                 '(bankrupt)' if world.is_bankrupt[aid] else ''\n",
    "                )\n",
    "        for aid, agent in world.agents.items():\n",
    "            if is_system_agent(aid):\n",
    "                continue\n",
    "            type_ = agent.type_name.split(':')[0].split('.')[-1]\n",
    "            type_scores[type_] += all_scores[aid]\n",
    "            counts[type_] += 1\n",
    "        type_scores = {k: v/counts[k] if counts[k] else v for k, v in type_scores.items()}\n",
    "    if draw:\n",
    "        world.draw(what=[\"contracts-signed\"], \n",
    "                       steps=(0, world.n_steps), together=True, ncols=1, figsize=(20, 20))\n",
    "        plt.show()\n",
    "    \n",
    "    return world, agent_scores, type_scores\n",
    "\n",
    "def analyze_contracts(world):\n",
    "    import pandas as pd\n",
    "    data = pd.DataFrame.from_records(world.saved_contracts)\n",
    "    # data = data.loc[(data[\"seller_name\"] == \"SELLER\")|(data[\"buyer_name\"]==\"BUYER\"), :]\n",
    "    return data.groupby([\"seller_name\", \"buyer_name\"])[[\"quantity\", \"unit_price\"]].mean().transpose()\n",
    "\n",
    "\n",
    "def print_agent_scores(agent_scores):\n",
    "    for aid, (type_, score, bankrupt) in agent_scores.items():\n",
    "        print(f\"Agent {aid} of type {type_} has a final score of {score} {bankrupt}\")\n",
    "        \n",
    "def print_type_scores(type_scores):\n",
    "    print(type_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to develop a do-nothing agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOneShotDoNothing(OneShotAgent):\n",
    "    \"\"\"My Agent that does nothing\"\"\"\n",
    "    def propose(self, negotiator_id, state):\n",
    "        return None\n",
    "    def respond(self, negotiator_id, state, offer):\n",
    "        return ResponseType.END_NEGOTIATION\n",
    "    \n",
    "world, ascores, tscores = try_agent(MyOneShotDoNothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all of the graph representing world simulations, we use short names that represent the type of the agent. For example an agent named `03Ran@1` is an agent of type `RandomOneShotAgent` at production level 1 that was the third agent to create. `MDN` here is a shorthand for `MyOneShotDoNothingAgent` (we will usually remove `OneShot` and `Agent` from the name before shortening it).\n",
    "\n",
    "Looking at the `contracts-concluded`, we can see that none of the concluded contracts involved our do-nothing agent. Nevertheless, these agents still had *exogenous contracts* which means that they will lose money. A do-nothing agent will usually lose money in this game.\n",
    "\n",
    "Let's check the scores of different agents to confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 00MDN@0 of type DefaultOneShotAdapter has a final score of 0.5144307050892224 \n",
      "Agent 01Ran@0 of type DefaultOneShotAdapter has a final score of 0.412241430259278 \n",
      "Agent 02MDN@0 of type DefaultOneShotAdapter has a final score of 1.0167077872394779 \n",
      "Agent 03Ran@1 of type DefaultOneShotAdapter has a final score of 0.3025954008783812 \n",
      "Agent 04Ran@1 of type DefaultOneShotAdapter has a final score of 0.3535653836811539 \n",
      "Agent 05MDN@1 of type DefaultOneShotAdapter has a final score of -0.8469711517364812 (bankrupt)\n"
     ]
    }
   ],
   "source": [
    "print_agent_scores(ascores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our do-nothing agent always loses money. That is because it cannot get any contracts from negotiation to satisfy its needs from the exogenous contracts but it still has to pay for storage cost and delivery penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MyOneShotDoNothing': 0.22805578019740638, 'RandomOneShotAgent': 0.35613407160627103}\n"
     ]
    }
   ],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the do-nothing agent is even worse than acting randomly. This is usually the case in the OneShot game.\n",
    "\n",
    "We can also have a look at the *exogenous* contracts that drive the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>seller_name</th>\n",
       "      <th colspan=\"2\" halign=\"left\">01Ran@0</th>\n",
       "      <th>03Ran@1</th>\n",
       "      <th>04Ran@1</th>\n",
       "      <th>05MDN@1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SELLER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buyer_name</th>\n",
       "      <th>03Ran@1</th>\n",
       "      <th>04Ran@1</th>\n",
       "      <th>BUYER</th>\n",
       "      <th>BUYER</th>\n",
       "      <th>BUYER</th>\n",
       "      <th>00MDN@0</th>\n",
       "      <th>01Ran@0</th>\n",
       "      <th>02MDN@0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quantity</th>\n",
       "      <td>4.7</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>8.111111</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.111111</td>\n",
       "      <td>9.500</td>\n",
       "      <td>9.625</td>\n",
       "      <td>10.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit_price</th>\n",
       "      <td>20.8</td>\n",
       "      <td>18.888889</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>9.875</td>\n",
       "      <td>11.250</td>\n",
       "      <td>10.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "seller_name 01Ran@0               03Ran@1    04Ran@1    05MDN@1  SELLER  \\\n",
       "buyer_name  03Ran@1    04Ran@1      BUYER      BUYER      BUYER 00MDN@0   \n",
       "quantity        4.7   6.333333   8.111111   8.000000  14.111111   9.500   \n",
       "unit_price     20.8  18.888889  22.666667  23.333333  22.222222   9.875   \n",
       "\n",
       "seller_name                  \n",
       "buyer_name  01Ran@0 02MDN@0  \n",
       "quantity      9.625  10.125  \n",
       "unit_price   11.250  10.125  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_contracts(world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few things to note about the distribution of the *exogenous* contracts:\n",
    "\n",
    "- The unit price of the raw material is always lower than that of the final product. This is the source of profitability in this market.\n",
    "- Each agent has a different mean and standar deviation for the quantities in its exogenous contracts. This means that different agents will have different utility functions but these utility functions for different steps are related because the exogenous contract is sampled from some common distribution for each agent for all the steps which makes learning more useful in the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building your own agent\n",
    "\n",
    "\n",
    "A one-shot agent needs only to do negotiation. The simplest possible version (`MyOneShotRandom` above) just responded to offers from its partners and proposed new offers to them. \n",
    "\n",
    "Looking at the graph for the world simulation, we can see immediately some features of the one-shot simulation that are not replicated in the full SCML game:\n",
    "\n",
    "- All negotiation requests are accepted. In fact in the one-shot game, the agent need not consider requesting negotiations or deciding the negotiation agenda as the system takes care of this ensuring that on every simulated day every agent is negotiating with its suppliers and or consumers about trade on that day (and only that day).\n",
    "- Contracts in the one-shot game are always executed (despite not showing that in the graph). There is no concept of a breach. Failure to honor contracts is instead penalized monetarily. Contracts are also never cancelled or nullified. This greatly simplifies the problem as the agent does not need to keep track of contract execution.\n",
    "- Production is too fast that it does not affect the agent reasoning. In the terminology to be presented in the following tutorial, there is no need for an explicit production strategy.\n",
    "- There is no need to consider future negotiations while reasoning about a the current set of negotiations. This greatly simplifies agent design as there is no long-term planning. In the terminology to be presented in the following section, there is no need for a trading strategy\n",
    "\n",
    "\n",
    "There are three base classes for one-shot agents (`OneShotAgent`, `SyncOneShotAgent`, and `SingleAgreementOneShotAgent`). We will discuss them in more details in what follows:\n",
    "\n",
    "### OneShotAgent\n",
    "\n",
    "This is the base class of all agents for SCML-OneShot. Both `SyncOneShotAgent` and `SingleAgreementOneShotAgent` inherit from this class and provide support for a simplified way of developing your agent (or so we think). It is perfectly OK to use `OneShotAgent` directly as the base of your agent.\n",
    "\n",
    "We have already seen the `OneShotAgent` class for which you need to override `propose` and may also override `respond` to handle negotiations independently. The `propose` method receives the negotiation state (an object of the type `SAOState` including among other things the current negotiation step, relative time, last offer, etc) and is required to return an `Outcome` (See `negmas` documentation) as an offer. The `respond` method receives a negotiation state and an offer (`Outcome`) from the opponent and needs to respond to it by a decision from the `ResponseType` enumeration (`REJECT_OFFER`, `ACCEPT_OFFER`, and `END_NEGOTIATION`). Other than these two negotiation related callbacks, the agent receives an `init` call just after it joins the simulatin and a `step` call after each step. The agent is also informed about failure/success of negotiations through the `on_negotiation_success`/`on_negotiation_failure` callbacks. That is all. A one-shot agent needs to only think about what should it do to respond to each of these six callbacks. All of these callbacks except `propose` are optional.\n",
    "\n",
    "#### Greedy OneShotAgent\n",
    "We have already seen how to develop a do-nothing agent using the `OneShotAgent` class. Let's try to develop some more meaningful agent using the same base class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyOneShotAgent(OneShotAgent):\n",
    "    \"\"\"A greedy agent based on OneShotAgent\"\"\"\n",
    "    \n",
    "    def init(self):\n",
    "        self.secured = 0\n",
    "                \n",
    "    def step(self):\n",
    "        self.secured = 0\n",
    "        \n",
    "    def on_negotiation_success(self, contract, mechanism):\n",
    "        self.secured += contract.agreement[\"quantity\"]\n",
    "\n",
    "    def propose(self, negotiator_id: str, state) -> \"Outcome\":\n",
    "        return self.best_offer(negotiator_id)\n",
    "\n",
    "    def respond(self, negotiator_id, state, offer):\n",
    "        my_needs = self._needed(negotiator_id)\n",
    "        if my_needs <= 0:\n",
    "            return ResponseType.END_NEGOTIATION\n",
    "        if state.step == self.negotiators[negotiator_id][0].ami.n_steps - 1:\n",
    "            return (\n",
    "                ResponseType.ACCEPT_OFFER\n",
    "                if offer[QUANTITY] <= my_needs\n",
    "                else ResponseType.REJECT_OFFER\n",
    "            )\n",
    "        return ResponseType.REJECT_OFFER\n",
    "    \n",
    "    def best_offer(self, negotiator_id):\n",
    "        my_needs = self._needed(negotiator_id)\n",
    "        if my_needs <= 0:\n",
    "            return None\n",
    "        quantity_issue = self.negotiators[negotiator_id][0].ami.issues[QUANTITY]\n",
    "        unit_price_issue = self.negotiators[negotiator_id][0].ami.issues[UNIT_PRICE]\n",
    "        offer = [-1] * 3\n",
    "        offer[QUANTITY] = max(\n",
    "            min(my_needs, quantity_issue.max_value), quantity_issue.min_value\n",
    "        )\n",
    "        offer[TIME] = self.awi.current_step\n",
    "        if self._is_selling(negotiator_id):\n",
    "            offer[UNIT_PRICE] = unit_price_issue.max_value\n",
    "        else:\n",
    "            offer[UNIT_PRICE] = unit_price_issue.min_value\n",
    "        return tuple(offer)\n",
    "\n",
    "    def _needed(self, negotiator_id):\n",
    "        return self.awi.current_exogenous_input_quantity + \\\n",
    "               self.awi.current_exogenous_output_quantity - \\\n",
    "               self.secured\n",
    "    \n",
    "    def _is_selling(self, negotiator_id):\n",
    "        return self.awi.is_first_level\n",
    "    \n",
    "world, ascores, tscores = try_agent(GreedyOneShotAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well did this agent behave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomOneShotAgent': 0.09102592462339269, 'GreedyOneShotAgent': 1.2027983369146653}\n"
     ]
    }
   ],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple agent is definitely better than the random agent. Let's understand how it works:\n",
    "\n",
    "The main idea of this agent is pretty simple. It tries to *secure* as much of its needs (sales/supplies) as possible in every negotiation at the best possible price for itself.\n",
    "\n",
    "To achieve this goal, the agent keeps track of the quantity it secured in its `init`, `step` and `on_negotiation_success` callbacks.\n",
    "\n",
    "```python\n",
    "def init(self):\n",
    "    self.secured = 0\n",
    "\n",
    "def step(self):\n",
    "    self.secured = 0\n",
    "\n",
    "def on_negotiation_success(self, contract, mechanism):\n",
    "    self.secured += contract.agreement[\"quantity\"]\n",
    "\n",
    "```\n",
    "\n",
    "Moreover, it defines a helper that calculates the amount it needs by subtracting the exogenous quantity it has from the amount it secured:\n",
    "\n",
    "```python\n",
    "def _needed(self):\n",
    "    return self.awi.current_exogenous_input_quantity + \\\n",
    "           self.awi.current_exogenous_output_quantity - \\\n",
    "           self.secured\n",
    "```\n",
    "\n",
    "Notice that either the exogenous input quantity or the exogenous output quantity (or both) will always be zero. Now that the agent can calculate how much it needs to buy/sell, it implements the negotiation related call-backs (`propose` and `respond`). \n",
    "\n",
    "Here is the full implementation of `propose`:\n",
    "```python\n",
    "def propose(self, negotiator_id: str, state) -> \"Outcome\":\n",
    "        return self.best_offer(negotiator_id)\n",
    "```\n",
    "\n",
    "The agent is always offering its best offer which is calculated in the `best_offer` method to be discussed later. It does not conceed at all.\n",
    "\n",
    "Responding to opponent offers is also simple:\n",
    "\n",
    "- it starts by calculating its needs using the helper `needed`, and ends the negotiation if it needs no more sales/supplies\n",
    "```python\n",
    "    my_needs = self._needed()\n",
    "    if my_needs <= 0:\n",
    "        return ResponseType.END_NEGOTIATION\n",
    "```\n",
    "- If this is the last step, and the quantity offered is less than the agent's needs it accepts it, otherwise, it rejects the offer.\n",
    "```python\n",
    "    if state.step == self.negotiators[negotiator_id][0].ami.n_steps - 1:\n",
    "        return (\n",
    "            ResponseType.ACCEPT_OFFER\n",
    "            if offer[QUANTITY] <= my_needs\n",
    "            else ResponseType.REJECT_OFFER\n",
    "        )\n",
    "    return ResponseType.REJECT_OFFER\n",
    "```\n",
    "\n",
    "Most of the code is in the `best_offer` method which calculates the best offer for a negotiation *given the agreements reached so far*. Let's check it line by line:\n",
    "\n",
    "- The agent checks its needs and returns `None` ending the negotiation if it needs no more sales/supplies\n",
    "```python\n",
    "    my_needs = self._needed()\n",
    "    if my_needs <= 0:\n",
    "        return None\n",
    "```\n",
    "\n",
    "- It then finds out the `Issue` objects corresponding to the quantity and unit-price for this negotiation and initializes an offer (we have 3 issues)\n",
    "```python\n",
    "    quantity_issue = self.negotiators[negotiator_id][0].ami.issues[QUANTITY]\n",
    "    unit_price_issue = self.negotiators[negotiator_id][0].ami.issues[UNIT_PRICE]\n",
    "    offer = [-1] * 3\n",
    "```\n",
    "- The time is always the current step\n",
    "```python    \n",
    "    offer[TIME] = self.awi.current_step\n",
    "```\n",
    "- The quantity to offer is simply the needs of the agent without mapped within the range of the quantities in the negotiation agenda (note that this may lead the agent to buy more than its needs). \n",
    "```python    \n",
    "    offer[QUANTITY] = max(\n",
    "        min(my_needs, quantity_issue.max_value), quantity_issue.min_value\n",
    "    )\n",
    "```\n",
    "- Finally, the unit price is the maximum possible unit price if the agent is selling otherwise it is the minimum possible price. Note that `is_selling()` assumes that the agent will never find itself in a middle layer in a deep negotiation. We will alleviate this issue later. \n",
    "```python\n",
    "    if self.is_selling():\n",
    "        offer[UNIT_PRICE] = unit_price_issue.max_value\n",
    "    else:\n",
    "        offer[UNIT_PRICE] = unit_price_issue.min_value\n",
    "    return tuple(offer)\n",
    "```\n",
    "That is it.\n",
    "\n",
    "#### More General Greedy Agent\n",
    "\n",
    "One issue that the `GreedyOneShotAget` had was that it assumed that it is either in the first level of the production chain or in the last level. To make an agent that works anywhere, we need just minor modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGreedyAgent(GreedyOneShotAgent):\n",
    "    \"\"\"A greedy agent based on OneShotSyncAgent that does something \n",
    "    when in the middle of the production chain\"\"\"\n",
    "    \n",
    "    def init(self):\n",
    "        self._sales = self._supplies = 0\n",
    "                \n",
    "    def step(self):\n",
    "        self._sales = self._supplies = 0\n",
    "        \n",
    "    def on_negotiation_success(self, contract, mechanism):\n",
    "        if contract.annotation[\"seller\"] == self.id:\n",
    "            self._sales += contract.agreement[\"quantity\"]\n",
    "        else:\n",
    "            self._supplies += contract.agreement[\"quantity\"]\n",
    "        \n",
    "    def _needed(self, negotiator_id):\n",
    "        summary = self.awi.exogenous_contract_summary\n",
    "        secured = self._sales if self._is_selling(negotiator_id) else self._supplies\n",
    "        return min(summary[0][0], summary[-1][0]) - secured\n",
    "        \n",
    "    def _is_selling(self, negotiator_id):\n",
    "        return self.negotiators[negotiator_id][0].ami.annotation[\"seller\"] == self.id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we now keep track of our sales and supplies separately:\n",
    "\n",
    "```python\n",
    "def init(self):\n",
    "        self._sales = self._supplies = 0\n",
    "                \n",
    "def step(self):\n",
    "    self._sales = self._supplies = 0\n",
    "\n",
    "def on_negotiation_success(self, contract, mechanism):\n",
    "    if contract.annotation[\"seller\"] == self.id:\n",
    "        self._sales += contract.agreement[\"quantity\"]\n",
    "    else:\n",
    "        self._supplies += contract.agreement[\"quantity\"]\n",
    "```\n",
    "\n",
    "To find out whether a contract is for sales or supplies, we simply check that the `seller` in the contract annotation is us. \n",
    "\n",
    "We need now two more changes:\n",
    "\n",
    "- Modify the way we know whether a contract is for sales or supplies. This is done by comparing the `seller` attribute of the annotation associated with the negotiator to our ID.\n",
    "\n",
    "```python\n",
    "def _is_selling(self, negotiator_id):\n",
    "    return self.negotiators[negotiator_id][0].ami.annotation[\"seller\"] == self.id\n",
    "```\n",
    "\n",
    "- The final modification, is to separate the calculation of our needs for supplies and sales:\n",
    "```python\n",
    "def _needed(self, negotiator_id):\n",
    "    summary = self.awi.exogenous_contract_summary\n",
    "    q = min(summary[0][0], summary[-1][0])\n",
    "    secured = self._sales if self._is_selling(negotiator_id) else self._supplies\n",
    "    n_competitors = len(self.awi.all_consumers[self.awi.my_input_product]\n",
    "    return int(q / n_competitors - secured)\n",
    "```\n",
    " here we start by reading the summary information of exogenous contracts into `summary`. This is a list of two valued tuples giving the **total** quantity and **total** price (in that order) of all current exogenous contracts for all products. We also find the amount we secured (depending on whether this is a buy or a sell negotiation) and the number of competitors (i.e. agents in the same production level as us). We assume that we need to buy (and sell) the same quantity as the minimum of the raw material and final product exogenous contracts divided equally between us and our competitors.\n",
    "\n",
    "Now, let's see how does this agent behave compared with the previous agent in a deep world simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "world, ascores, tscores = try_agents([DeepGreedyAgent, GreedyOneShotAgent], n_processes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the graph above, we can clearly see that `GreedyOneShotAgent` objects in the middle layers did not get any contracts (can you see why?) while `DeepGreedyAgent` could.\n",
    "We can also check the scores as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GreedyOneShotAgent': 0.8033444083372799, 'DeepGreedyAgent': 0.17148779195707844}\n"
     ]
    }
   ],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our new `DeepGreedyAgent` was able to get contracts which in the middle, it seems that it did worse than `GreedyOneShotAgent` in terms of final profits. This may be just a quirk of this specific configuration. We will leave it to the reader to investigate this issue (if they choose to).\n",
    "\n",
    "Given that the utility function of the agent is defined in terms of a *complete set of contracts*, it is not trivial to define a utility function for each negotiation independent from the others (which is why this is an inherently concurrent negotiation world). It may be easier then to think of all negotiations in a synchronized manner. This means that the agent keeps collecting offers from its partners and when it has a *complete set*, it responds to all of them. Moreover, to start negotiations in which the agent finds itself the first propsoer, it needs to define a first proposal for each negotiation. This is why `SyncOneShotAgent` allows you to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SyncOneShotAgent\n",
    "\n",
    "The main goal of this base agent is to allow the developer to think about *all negotiations together* but it has some important caveats which we will discuss later.\n",
    "Here is an example of writing the do-nothing agent in this form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from negmas import SAOResponse\n",
    "class MySyncOneShotDoNothing(OneShotSyncAgent):\n",
    "    \"\"\"My Agent that does nothing\"\"\"\n",
    "    def counter_all(self, offers, states):\n",
    "        \"\"\"Respond to a set of offers given the negotiation state of each.\"\"\"\n",
    "        return dict(zip(self.negotiators.keys(), [SAOResponse(ResponseType.END_NEGOTIATION, None)] * len(self.negotiators)))\n",
    "    \n",
    "    def first_proposals(self):\n",
    "        \"\"\"Decide a first proposal on every negotiation. Returning None for a negotiation means ending it.\"\"\"\n",
    "        return dict(zip(self.negotiators.keys(), [None] * len(self.negotiators)))\n",
    "    \n",
    "world, ascores, tscores = try_agent(MySyncOneShotDoNothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in this case, we need to override `counter_all` to counter offers received from *all* the partners and `first_proposals` to decide a first offer for *each* partner. Notice that this is a many-to-many negotiation scenario. This means that if multiple agents at every level are using sync variants, loops may happen with the possiblity of a deadlock. \n",
    "\n",
    "For that reason the system will randomly break such loops when they happen which implies that **`counter_all` may receive a subset of the offers from partners not all of them**. In the worst case, `counter_all` may receive just one offer each time from one of the partners losing all synchronity between responses.\n",
    "\n",
    "Other than these two negotiation related callbacks, the agent receives an `init` call just after it joins the simulatin and a `step` call after each step. The agent is also informed about failure/success of negotiations through the `on_negotiation_success`/`on_negotiation_failure` callbacks. That is all. A one-shot agent needs to only think about what should it do to respond to each of these six callbacks. All of these callbacks except `counter_all` and `first_proposals` are optional.\n",
    "\n",
    "#### GreedySyncAgent\n",
    "\n",
    "The main advantage of using the `OneShotSyncAgent` is that you do not need to keep track of state variables (like `secured`, `_supplies` and `_sales` used earlier) and you have a common place to make your decisions about **all** negotiations at the same time. Here is a simple greedy agent using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySyncAgent(OneShotSyncAgent, GreedyOneShotAgent):\n",
    "    \"\"\"A greedy agent based on OneShotSyncAgent\"\"\"\n",
    "    \n",
    "    def first_proposals(self):\n",
    "        \"\"\"Decide a first proposal on every negotiation. \n",
    "        Returning None for a negotiation means ending it.\"\"\"\n",
    "        return dict(zip(\n",
    "                self.negotiators.keys(), \n",
    "                (self.best_offer(_) for _ in self.negotiators.keys())\n",
    "        ))\n",
    "    \n",
    "    def counter_all(self, offers, states):\n",
    "        \"\"\"Respond to a set of offers given the negotiation state of each.\"\"\"\n",
    "        responses = {\n",
    "            k: SAOResponse(ResponseType.REJECT_OFFER, _) \n",
    "            for k, v in self.first_proposals().items()\n",
    "        }\n",
    "        my_needs = self._needed(None)\n",
    "        sorted_offers = sorted(\n",
    "            zip(offers.values(), (self._is_selling(_) for _ in offers.keys())), \n",
    "            key=lambda x: (- x[0][UNIT_PRICE]) if x[1] else x[0][UNIT_PRICE]\n",
    "        )\n",
    "        secured, outputs, chosen = 0, [], dict()\n",
    "        for i, k in enumerate(offers.keys()):\n",
    "            offer, is_output = sorted_offers[i]\n",
    "            secured += offer[QUANTITY]\n",
    "            if secured >= my_needs:\n",
    "                break\n",
    "            chosen[k] = offer\n",
    "            outputs.append(is_output)\n",
    "            \n",
    "        u = self.ufun.from_offers(list(chosen.values()), outputs)\n",
    "        if u > 0.7 * self.ufun.max_utility:\n",
    "            for k, v in chosen.items():\n",
    "                responses[k] = SAOResponse(ResponseType.ACCEPT_OFFER, None)\n",
    "        return responses\n",
    "    \n",
    "world, ascores, tscores = try_agent(GreedySyncAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to implement two methods: `first_proposals` (to generate a good first proposal for each negotiation) and `counter_all` (for countering a set of offers). We inherit from `GreedyOneShotAgent` in order to get access to `best_offer` and `_is_selling` methods (we could have repeated them here again of course. Note that, because of the way inheritence works in python, we must inherit from `OneShotSyncAgent` before `GreedyOneShotAgent`.\n",
    "\n",
    "The first set of proposals in `first_proposals` is simply the `best_offer` for each negotiation which is calculated using this generator expression:\n",
    "```python\n",
    "(self.best_offer(_) for _ in self.negotiators.keys())\n",
    "```\n",
    "\n",
    "Almost all the code now resides in the `counter_all` method. We will go over it here:\n",
    "\n",
    "- We start by initializing our response by the best offer for each negotiation using `first_proposals` and calculating our needs using `_needed`\n",
    "```python\n",
    "responses = self.first_proposals()\n",
    "outputs = list()\n",
    "my_needs = self._needed(None)\n",
    "```\n",
    "\n",
    "- We then sort the offers so that earlier offers have *better* prices for us. For sell offers, this means descendingly and for buy offers ascendingly.\n",
    "```python\n",
    "sorted_offers = sorted(\n",
    "    zip(offers.values(), (self._is_selling(_) for _ in offers.keys())), \n",
    "    key=lambda o, nid: - o[UNIT_PRICE] if self._selling(o) else o[UNIT_PRICE]\n",
    ")\n",
    "```\n",
    "- We *greedily* find a set of offers that satisfy all our needs (or as much as possible from them). \n",
    "```python\n",
    "secured, chosen = 0, dict()\n",
    "for i, k in enumerate(offers.keys()):\n",
    "    offer, is_output = sorted_offers[i]\n",
    "    secured += offer[QUANTITY]\n",
    "    if secured >= my_needs:\n",
    "        break\n",
    "    chosen[k], outputs[k] = offer, is_output\n",
    "```\n",
    "- Finally, we calculate the utility of accepting these *and only these* offers and accept the chosen offers if they provide 70% of the maximum possible utility. Otherwise, we reject all offers sending the default `best_offer` value back.\n",
    "```python\n",
    "u = self.ufun.from_offers(offers, outputs)\n",
    "if u > 0.7 * self.ufun.max_utility:\n",
    "    for k, v in chosen.items():\n",
    "        responses[k] = SAOResponse(ResponseType.ACCEPT_OFFER, None)\n",
    "```\n",
    "\n",
    "Let's see how did it work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GreedySyncAgent': 0.9454329783105758, 'RandomOneShotAgent': 0.15131402721267798}\n"
     ]
    }
   ],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This base-class simplifies the job of the agent developer by providing a single function (`counter_all`) in which to handle all offers it receive (most of the time, remember that sometimes you will receive a subset of the offers in the call). In principle the agent can then decide to accept a few of these offers and keep negotiating. \n",
    "\n",
    "In many cases, it may be possible to secure all of the agent's needs (i.e. supplies or sales) using a **single** contract with one of its partners. In such cases, the agent can think about the negotiations it is engaged in as a **competetive negotiation** not very dissimilar from an auction that also allows it to offer. This can lead to a further simplification, the agent can be designed to get **at most one agreement** from the set of negotiation and end all the rest once this is achieved. This is what the `SingleAgreementOneShotAgent` does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SingleAgreementOneShotAgent\n",
    "This base classs allows you to develop agents that can get **at most** one agreement from the set of negotiation at every simulation step. \n",
    "\n",
    "This controller manages a set of negotiations from which only a single one\n",
    "-- at most -- is likely to result in an agreement. To guarentee a single agreement, pass ```strict=True```.\n",
    "\n",
    "The general algorithm for this controller is something like this:\n",
    "\n",
    "- Receive offers from all partners.\n",
    "- Find the best offer among them by calling the abstract `best_offer`\n",
    "  method.\n",
    "- Check if this best offer is acceptable using the abstract `is_acceptable`\n",
    "  method.\n",
    "\n",
    "    - If the best offer is acceptable, accept it and end all other negotiations.\n",
    "    - If the best offer is still not acceptable, then all offers are rejected\n",
    "      and with the partner who sent it receiving the result of `best_outcome`\n",
    "      while the rest of the partners receive the result of `make_outcome`.\n",
    "\n",
    "- The default behavior of `best_outcome` is to return the outcome with\n",
    "  maximum utility.\n",
    "- The default behavior of `make_outcome` is to return the best offer\n",
    "  received in this round if it is valid for the respective negotiation\n",
    "  and the result of `best_outcome` otherwise.\n",
    "  \n",
    "To use this agent, you need to implement three methods:\n",
    "\n",
    "- `is_acceptable` decides whether an offer is now acceptable. For this simple agent, we accept an offer if it provides us with at least 70% of the maximum possible utility.\n",
    "```python\n",
    "return self.ufun(offer) > 0.7 * self.ufun.max_utility\n",
    "```\n",
    "- `best_offer` finds the best offer among a set of offers. Here we simply compare their utility\n",
    "```python\n",
    "ufuns = [(self.ufun(_), i) for i, _ in enumerate(offers.values())]\n",
    "keys = list(offers.keys())\n",
    "return keys[max(ufuns)[1]]\n",
    "```\n",
    "- `is_better` which compares two offers from the same negotiator. We simply compare their utility value:\n",
    "```python\n",
    "return self.ufun(a) > self.ufun(b)\n",
    "```\n",
    "\n",
    "Here is the full agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySingleAgreementAgent(OneShotSingleAgreementAgent):\n",
    "    \"\"\"A greedy agent based on OneShotSingleAgreementAgent\"\"\"   \n",
    "\n",
    "    def init(self):\n",
    "        self.__endall = self.awi.is_middle_level\n",
    "            \n",
    "    def is_acceptable(self, offer, source, state) -> bool:\n",
    "        if self.__endall:\n",
    "            return False\n",
    "        return self.ufun(offer) > 0.7 * self.ufun.max_utility\n",
    "\n",
    "    def best_offer(self, offers):\n",
    "        ufuns = [(self.ufun(_), i) for i, _ in enumerate(offers.values())]\n",
    "        keys = list(offers.keys())\n",
    "        return keys[max(ufuns)[1]]\n",
    "\n",
    "    def is_better(self, a, b, negotiator, state):\n",
    "        return self.ufun(a) > self.ufun(b)\n",
    "\n",
    "world, ascors, tscores = try_agent(GreedySingleAgreementAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GreedySingleAgreementAgent': 0.6358373222467085, 'RandomOneShotAgent': 0.10649968288273226}\n"
     ]
    }
   ],
   "source": [
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing all agents\n",
    "\n",
    "Let's run a tournament comparing all agents we developed in this tutorial (we will ignore the do-nothing agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GreedyOneShotAgent': 0.013371327855547127, 'GreedySingleAgreementAgent': 0.013929766141146858, 'GreedySyncAgent': 0.0048692321730847005}\n"
     ]
    }
   ],
   "source": [
    "# may take a long time\n",
    "_, _, tscores = try_agents(\n",
    "    [GreedyOneShotAgent, GreedySingleAgreementAgent, GreedySyncAgent], \n",
    "    n_trials=40, \n",
    "    n_processes=(2, 4),\n",
    "    draw=False\n",
    ")\n",
    "print_type_scores(tscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we just compared these agents is not unbiased because not all agents are allowed to control the same factories in the same simulation envoironment. The best way to compare these agents is to run a tournament between them. You already learned how to do that in the previous tutorial and we will not repeate it here.\n",
    "\n",
    "*If you are running this notebook, please note that the tournament running methods `anac2021_*` may not work within a notebook environment. You can just move your code to a normal python script and it will run correctly*\n",
    "\n",
    "\n",
    "You can find all the agents available in the `scml` package for the one-shot game under `scml.oneshot.agents` including the ones developed in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RandomOneShotAgent', 'SyncRandomOneShotAgent', 'SingleAgreementRandomAgent', 'SingleAgreementAspirationAgent', 'GreedyOneShotAgent', 'GreedySyncAgent', 'GreedySingleAgreementAgent', 'OneshotDoNothingAgent']\n"
     ]
    }
   ],
   "source": [
    "import scml.oneshot.agents as agents\n",
    "print([ _ for _ in agents.__dir__() if _.endswith(\"Agent\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we end our tutorial. Have fun developing your agent."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
